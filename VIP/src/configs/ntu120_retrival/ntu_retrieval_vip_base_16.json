{
    "train_datasets": 
      {
        "name": "ntu_train",
        "vis_format": "video",
        "txt": "/home/bas06400/Thesis/CLIPVIP_Datasets/annotations_rgb_comp_CV_training_120set.jsonl",
        "vis": "/net/polaris/storage/deeplearning/ntu/nturgb+d_rgb_low_res2"
      },
    "val_datasets": [
  
      {
        "name": "ntu_val",
        "vis_format": "video",
        "txt": "/home/bas06400/Thesis/CLIPVIP_Datasets/unique_samples120test.jsonl",
        "vis": "/net/polaris/storage/deeplearning/ntu/nturgb+d_rgb_low_res2"
      }
    ],
    "inference_datasets": [
      {
        "name": "ntu_test",
        "vis_format": "video",
        "txt": "/home/bas06400/Thesis/CLIPVIP_Datasets/unique_samples120test.jsonl",
        "vis": "/net/polaris/storage/deeplearning/ntu/nturgb+d_rgb_low_res2"
      }
    ],
  
    "train_n_clips": 1,
    "train_num_frms": 12,
    "test_n_clips": 1,
    "test_num_frms": 12,
    "sample_rate": 0,
    "sample_jitter": 1,
    "video_res": [240, 320],
    "input_res": [224, 224],
    "max_txt_len": 50,
  
    "e2e_weights_path": "/home/bas06400/Thesis/pretrain_clipvip_base_16.pt",
    "clip_weights": "openai/clip-vit-base-patch16",
    "clip_config": "openai/clip-vit-base-patch16",
    "clip_vision_additional_config": {
        "type": "ViP",
        "temporal_size": 12,
        "if_use_temporal_embed": 1,
        "logit_scale_init_value": 4.60,
        "add_cls_num": 3
    },
  
    "train_batch_size": 64,
    "test_batch_size": 128,
    "max_n_example_per_group": 1,
    "gradient_accumulation_steps": 1,
    "n_workers": 10,
    "pin_mem": 1,
    "fp16": 1,
    "amp_level": "O2",
    "seed": 42,
  
    "optim": "adamw",
    "betas": [0.9, 0.98],
    "learning_rate": 1e-6,
    "weight_decay": 0.1,
    "lr_mul": 1,
    "lr_mul_prefix": "",
    "loss_config": {
      "loss_name": "NCELearnableTempDSLLoss",
      "if_gather": 1
    },
    "warmup_ratio": 0.01,
    "decay": "cosine",
    "grad_norm": 1.0,
  
    "num_train_epochs": 10,
    "min_valid_steps": 1,
    "num_valid": 5,
    "only_valid_steps": 160,
    "save_steps_ratio": 0.9,
    "output_dir": "vidclip_data/output/msrvtt_retrieval/msrvtt_retrieval_vip_base_16",
    "if_tb_log": 0,
    "if_model_saver": 1,
    "if_log2file": 1,
    "dummy_data": 0
  }
  
  