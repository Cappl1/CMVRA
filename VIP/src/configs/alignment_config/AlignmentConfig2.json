{
    "task": "1",
    "topic": "ft_bs16_16",
    "number_gpus": "1",
    "align_pre_training": false,
    "bind_to_rgb": true,
    "modalities": [
        "rgb",
        "ir"
    ],
    "encoder_model": "MIX",
    "modalities_encoders": {
        "rgb": "CLIP-VIP",
        "ir": "OMNIVORE"
    },
    "dataset": "DAA",
    "split": "zs",
    "overfit_on_one_batch": false,
    "augs":true,
    "num_classes": 34,
    "in_features": 512,
    "epochs": 10,
    "res_cktp": false,
    "cktp_dir": "/home/bas06400/Thesis/VIP/src/align_checkpoints",
    "aligned_model": "",
    "learning_rate": 0.0001,
    "gradient_accumulation_steps": 2,
    "scheduler_config": {
        "type": "step",
        "params": {
            "step_size": 4,
            "gamma": 0.1
        }
    },
    "temperature": 0.1,
    "num_workers": 5,
    "data_list": "/home/bas06400/Thesis/rgb_ir_dataset.txt",
    "data_root": "/net/polaris/storage/deeplearning/ntu",
    "batch_size": 16,
    "random_sample": false,
    "pin_memory": true,
    "clip_config": "openai/clip-vit-base-patch16",
    "clip_weights": "openai/clip-vit-base-patch16",
    "clip_vision_additional_config": {
        "type": "ViP",
        "temporal_size": 12,
        "if_use_temporal_embed": true,
        "logit_scale_init_value": 4.6,
        "add_cls_num": 3
    },
    "e2e_weights_path": "/home/bas06400/Thesis/VIP/src/vidclip_data/output/msrvtt_retrieval/msrvtt_retrieval_vip_base_16/ckpt/zs0_bs16_model_step_12237.pt"
}